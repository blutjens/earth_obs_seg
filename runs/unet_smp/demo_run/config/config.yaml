# This config.yaml is to demo the use of this template repository

# Here's where you define experiment-specific hyperparameters.
# You can also create lists and group parameters together into nested sub-parts.
# In Python, this is all read as a dict.

# environment/computational parameters
seed: 42
# device: cpu
num_workers: 4
use_deterministic_algorithms: True # set torch layers to deterministic or raises error
dtype: 'float32' # datatype for in-, output and model weights

model_key: 'unet_smp'           # unique ID for chosen model that is used across filenames, logs, etc.
encoder_name: 'resnet34'        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7
encoder_weights: 'imagenet'     # use `imagenet` pre-trained weights for encoder initialization
in_channels: 3                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)
out_channels: 1                 # number of model output channels, e.g., 1 for binary classification

# Replace <demo_run> with the name of your data split
experiment_key: 'demo_run'
path_data: './data/hrmelt_sample/' # Replace this with your data path
path_checkpoints: './runs/unet_smp/demo_run/checkpoints' # Store model checkpoints
path_train_split_csv: './runs/unet_smp/demo_run/config/train.csv' # Image filenames used during training
path_val_split_csv: './runs/unet_smp/demo_run/config/val.csv' # Image filenames used during validation
path_test_split_csv: './runs/unet_smp/demo_run/config/test.csv'  # Image filenames used during test
# Choose channels that should be used as model inputs
in_keys: ['pmw', 'mar_wa1']
in_keys_static: []
# These are the full paths to every channel the dataloader should have access to
path_mar_wa1: './data/hrmelt_sample/MAR/MARv3.12/WA1/'
path_pmw: './data/hrmelt_sample/PMW/'
path_melt: './data/hrmelt_sample/SAR/'
# Paths to static variables
path_landmask: './data/hrmelt_sample/landmask/landMask_100m.tif'
path_dem: './data/hrmelt_sample/DEM/dem_100m.tif'

# Normalization information. 
# mean and standard deviation are calculated across the full dataset
mean_pmw: 206.1035919189453
mean_mar_wa1: 0.005986050236970186
mean_melt: 0.1931522637605667
mean_dem: 1175.09423828125
std_pmw: 30.67822265625
std_mar_wa1: 0.01700020208954811
std_melt: 0.4618076921046514
std_dem: 993.8524169921875
normalize_inputs: True
max_mar_wa1: 1.

# training hyperparameters
epochs: 100
batch_size: 2
img_size: [128,128] # height and width of tile
optimizer: 'adamW' # Optimization algorithm
learning_rate: 0.0001
weight_decay: 0.
loss_function: 'dice' # E.g., 'dice' for binary image segmentation

# Data transformation and augmentation parameters
#  GaussianBlur is applied deterministic and smoothes out sharp edges in input 
pmw_GaussianBlur_kernel_size: 45. # Default 1. equals no augmentation
pmw_GaussianBlur_sigma: 15. # Default 1. equals no augmentation

# Step learning rate scheduler 
lr_scheduler: 'ReduceLROnPlateau'
lr_patience: 100 # Number of steps on validation loss platenau until lr scheduler reduces lr

# CosineAnnealingWarmRestarts lerning rate scheduler
# lr_scheduler: 'CosineAnnealingWarmRestarts'
T_0: 35 # Number of epochs until first restart; 
T_mult: 2 # A factor increases Ti after a restart. 
# To understand this see: https://towardsdatascience.com/a-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863
# E.g., First restart after T_0 epochs and then 2nd restart after T_0*T_mult epochs
# With T_0 = 35 and T_mult = 2, the training can be nicely stopped at 525 epochs: (1+ 2+ 4+ 8) *35 = 525
eta_min: 0. # Minimum learning rate. Default: 0.
